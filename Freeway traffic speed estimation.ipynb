{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled33.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7DlZ-3b7-3u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "# load data\n",
        "##################################\n",
        "data1 = pd.read_csv()\n",
        "data2 = pd.read_csv()\n",
        "\n",
        "\n",
        "# data processing\n",
        "##################################\n",
        "data1['5 Minutes'] = pd.to_datetime(data1['5 Minutes'])\n",
        "data1['minute'] = data1['5 Minutes'].dt.minute\n",
        "data1['hour'] = data1['5 Minutes'].dt.hour\n",
        "\n",
        "def scale_feature(data1,feat):\n",
        "    data1[feat] = data1[feat] / data1[feat].max() \n",
        "    return data1\n",
        "\n",
        "def split_trainNtest(data1,date):\n",
        "    train = data1[data1['5 Minutes'] <= pd.to_datetime(date)]\n",
        "    test = data1[data1['5 Minutes'] > pd.to_datetime(date)]\n",
        "    return train,test\n",
        "\n",
        "def one_hot_feature(data1):\n",
        "    data1 = pd.get_dummies(data1)\n",
        "    return data1\n",
        "\n",
        "data1['Day of Week'] = data1['Day of Week'].astype(str)\n",
        "data1['minute'] = data1['minute'].astype(str)\n",
        "data1['hour'] = data1['hour'].astype(str)\n",
        "\n",
        "scale_cols = ['speed 1','flow 1']\n",
        "\n",
        "train = data1\n",
        "\n",
        "label = ['speed 2']\n",
        "del_col = ['5 Minutes',\n",
        "           'flow 2',\n",
        "           'speed 2']\n",
        "\n",
        "train_label = train[label]\n",
        "train_feat = train.drop(del_col,axis=1)\n",
        "\n",
        "train_feat = np.array(train_feat)\n",
        "train_label = np.array(train_label)\n",
        "\n",
        "\n",
        "data2['5 Minutes'] = pd.to_datetime(data2['5 Minutes'])\n",
        "data2['minute'] = data2['5 Minutes'].dt.minute\n",
        "data2['hour'] = data2['5 Minutes'].dt.hour\n",
        "\n",
        "def scale_feature(data2,feat):\n",
        "    data2[feat] = data2[feat] / data2[feat].max() \n",
        "    return data2\n",
        "\n",
        "\n",
        "def one_hot_feature(data2):\n",
        "    data2 = pd.get_dummies(data2)\n",
        "    return data2\n",
        "\n",
        "\n",
        "data2['Day of Week'] = data2['Day of Week'].astype(str)\n",
        "data2['minute'] = data2['minute'].astype(str)\n",
        "data2['hour'] = data2['hour'].astype(str)\n",
        "\n",
        "\n",
        "scale_cols = ['speed 1',\n",
        "              'flow 1'\n",
        "             ]\n",
        "\n",
        "test = data2\n",
        "\n",
        "label = ['speed 2']\n",
        "del_col = ['5 Minutes', 'flow 2', 'speed 2']\n",
        "\n",
        "test_label = test2[label]\n",
        "test_feat = test2.drop(del_col,axis=1)\n",
        "test_feat = np.array(test_feat2)\n",
        "test_label = np.array(test_label2)\n",
        "\n",
        "# SVM\n",
        "############################\n",
        "from sklearn.svm import SVR\n",
        "import numpy as np\n",
        "SVR = SVR(gamma='scale', C=1000, epsilon=0.1)\n",
        "SVR.fit(train_feat, train_label)\n",
        "\n",
        "# prediction\n",
        "############################\n",
        "model_pre = SVR.predict(test_feat)\n",
        "\n",
        "def mean_absolute_percentage_error(y_true, y_pred):\n",
        "  y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "  return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn import metrics\n",
        "y_true = test_label.flatten()\n",
        "y_pred = model_pre\n",
        "\n",
        "print(metrics.r2_score(y_true,y_pred))\n",
        "print(np.sqrt(metrics.mean_squared_error(y_true,y_pred)))\n",
        "print(mean_absolute_percentage_error(y_true, y_pred))\n",
        "\n",
        "# RF\n",
        "############################\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "RF = RandomForestRegressor(n_estimators= 200,random_state=42)\n",
        "RF.fit(train_feat, train_label)\n",
        "\n",
        "# prediction\n",
        "############################\n",
        "model_pre = RF.predict(test_feat)\n",
        "\n",
        "y_true = test_label.flatten()\n",
        "y_pred = model_pre\n",
        "\n",
        "print(metrics.r2_score(y_true,y_pred))\n",
        "print(np.sqrt(metrics.mean_squared_error(y_true,y_pred)))\n",
        "print(mean_absolute_percentage_error(y_true, y_pred))\n",
        "\n",
        "# GBDT\n",
        "############################\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "GBoost = GradientBoostingRegressor(n_estimators=1500, learning_rate=0.3,\n",
        "                                   max_depth=4, max_features='sqrt',\n",
        "                                   min_samples_leaf=15, min_samples_split=10, \n",
        "                                   loss='huber', random_state =60)\n",
        "GBoost.fit(train_feat, train_label)\n",
        "\n",
        "\n",
        "# prediction\n",
        "############################\n",
        "model_pre = GBoost.predict(test_feat)\n",
        "\n",
        "y_true = test_label.flatten()\n",
        "y_pred = model_pre\n",
        "\n",
        "print(metrics.r2_score(y_true,y_pred))\n",
        "print(np.sqrt(metrics.mean_squared_error(y_true,y_pred)))\n",
        "print(mean_absolute_percentage_error(y_true, y_pred))\n",
        "\n",
        "# XGB\n",
        "############################\n",
        "import xgboost as xgb\n",
        "\n",
        "model_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
        "                             learning_rate=0.05, max_depth=5, \n",
        "                             min_child_weight=1.7817, n_estimators=2000,\n",
        "                             reg_alpha=0.4640, reg_lambda=0.8571,\n",
        "                             subsample=0.5213, silent=1,\n",
        "                             random_state =7, nthread = -1)\n",
        "model_xgb.fit(train_feat, train_label)\n",
        "\n",
        "# prediction\n",
        "############################\n",
        "model_pre = model_xgb.predict(test_feat)\n",
        "\n",
        "y_true = test_label.flatten()\n",
        "y_pred = model_pre\n",
        "\n",
        "print(metrics.r2_score(y_true,y_pred))\n",
        "print(np.sqrt(metrics.mean_squared_error(y_true,y_pred)))\n",
        "print(mean_absolute_percentage_error(y_true, y_pred))\n",
        "\n",
        "\n",
        "# ANN\n",
        "#############################\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "ANN = MLPRegressor(learning_rate_init=0.001,batch_size=20,tol=0.01,learning_rate='constant',hidden_layer_sizes=(1000,),solver='adam')\n",
        "ANN.fit(train_feat, train_label)\n",
        "\n",
        "# prediction\n",
        "############################\n",
        "model_pre = mANN.predict(test_feat)\n",
        "\n",
        "y_true = test_label.flatten()\n",
        "y_pred = model_pre\n",
        "\n",
        "print(metrics.r2_score(y_true,y_pred))\n",
        "print(np.sqrt(metrics.mean_squared_error(y_true,y_pred)))\n",
        "print(mean_absolute_percentage_error(y_true, y_pred))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}